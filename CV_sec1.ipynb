{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Drawing on an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we’re going to draw a rectangle, circle, and line on an input image. We’ll also overlay text on an image as well.\n",
    "\n",
    "Before we move on with drawing on an image with OpenCV, take note that drawing operations on images are performed in-place. Therefore at the beginning of each code block, we make a copy of the original image storing the copy as output . We then proceed to draw on the image called output in-place so we do not destroy our original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement opencv-puthon (from versions: none)\n",
      "ERROR: No matching distribution found for opencv-puthon\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-puthon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Drawing Rectangle</h3>\n",
    "\n",
    "In a similar we can draw a rectangle.Here is the the syntax for this function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li><b>img : </b>The destination image to draw upon. We’re drawing on output .\n",
    "<li><b>pt1 : </b>Our starting pixel coordinate which is the top-left. In our case, the top-left is (320, 60) .\n",
    "<li><b>pt2 : </b>The ending pixel — bottom-right. The bottom-right pixel is located at (420, 160) .\n",
    "<li><b>color : </b> BGR tuple. To represent red, I’ve supplied (0 , 0, 255) .\n",
    "<li><b>thickness :</b> Line thickness (a negative value will make a solid rectangle). I’ve supplied a thickness of 2 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw a 2px thick red rectangle surrounding the face\n",
    "import cv2\n",
    "#import imutils\n",
    "image = cv2.imread(r\"C:\\Users\\Elhamd Pc\\Pictures\\Screenshots\\Screenshot 2023-10-10 230514.png\")\n",
    "output = image.copy()\n",
    "cv2.rectangle(output, (320, 60), (420, 160), (0, 0, 255), 2)\n",
    "cv2.imshow(\"Rectangle\", output)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Drawing circle:</h3>\n",
    "We use the method to circle to draw a circle in an image.Here is the syntax and parameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Syntax: cv2.circle(image, center_coordinates, radius, color, thickness)\n",
    "Parameters: \n",
    "<li>image:</b> It is the input image on which a circle is to be drawn. \n",
    "<li><b>center_coordinates: </b>It is the center coordinates of the circle. The coordinates are represented as tuples of two values i.e. (X coordinate value, Y coordinate value). \n",
    "<li><b>radius: </b>It is the radius of the circle. \n",
    "<li><b>color: </b>It is the color of the border line of the circle to be drawn. We can pass a tuple For in BGR,  eg: (255, 0, 0) for blue color. \n",
    "<li><b>thickness:</b> It is the thickness of the circle border line in px. Thickness of -1 px will fill the circle shape by the specified color.\n",
    "<li><b>Return Value: </b>It returns an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw a blue 20px (filled in) circle on the image centered at\n",
    "# x=300,y=150\n",
    "output = image.copy()\n",
    "cv2.circle(output, (300, 150), 20, (255, 0, 0), -1)\n",
    "cv2.imshow(\"Circle\", output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Drawing Lines</h3>\n",
    "\n",
    "Here is the syntax of the line method using which we can make lines on an image.<br>\n",
    "\n",
    "<li><b>Syntax: cv2.line(image, start_point, end_point, color, thickness)</b>\n",
    "\n",
    "    <b>Parameters:</b>\n",
    "<li><b>image: </b>It is the input image on which line is to be drawn.\n",
    "<li><b>start_point: </b>It is the starting coordinates of the line. The coordinates are represented as tuples of two values i.e. (X coordinate value, Y coordinate value).\n",
    "<li><b>end_point:</b> It is the ending coordinates of the line. The coordinates are represented as tuples of two values i.e. (X coordinate value, Y coordinate value).\n",
    "<li><b>color: </b>It is the color of the line to be drawn. We can pass a tuple For in BGR,  eg: (255, 0, 0) for blue color. \n",
    "<li><b>thickness:</b> It is the thickness of the line in px.\n",
    "\n",
    "<li><b>Return Value:</b> It returns an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw a 5px thick red line from x=60,y=20 to x=400,y=200\n",
    "output = image.copy()\n",
    "cv2.line(output, (60, 20), (400, 200), (0, 0, 255), 5)\n",
    "cv2.imshow(\"Line\", output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllwindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Drawing Polylines</h3>\n",
    "\n",
    "draw the polylines using the polylines() method on the image. And these can be used to draw polygonal curves on the image. The syntax is given below:<br>\n",
    "syntax\n",
    "cv2.polyLine(image, arr, is_closed, color, thickness)  \n",
    "<b>Parameters:</b>\n",
    "<li><b>img - </b>It represents an image.\n",
    "<li><b>arr -</b>represents the coordinates of vertices into an array of shape nx1x2 where n is number of vertices and it should be of type int32.\n",
    "<li><b>is_Closed - </b>It is a flag that indicates whether the drawn polylines are closed or not.\n",
    "<li><b>color - </b>Color of polylines. We can pass a tuple For in BGR,  eg: (255, 0, 0) for blue color. \n",
    "<li><b>thickness - </b>It represents the Thickness of the polyline's edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import cv2  \n",
    "img = cv2.imread(r\"C:\\Users\\Elhamd Pc\\Pictures\\Screenshots\\Screenshot 2023-10-10 230514.png\", 1)  \n",
    "#defining points for polylines  \n",
    "pts = np.array([[100,50],[200,300],[350,200],[350,100]], np.int32)  \n",
    "#pts = pts.reshape((-1,1,2))  \n",
    "cv2.polylines(img, [pts], True, (0,255,255), 3)  \n",
    "cv2.imshow('image',img)  \n",
    "cv2.waitKey(0)  \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Write text on an image</h3>\n",
    "\n",
    "We can write text on the image by using the putText() method. The syntax is given below.<br>\n",
    "<b>Syntax</b>\n",
    "cv2.putText(img, text, org, font,fontScale color)  \n",
    "<b>Parameters:</b>\n",
    "<li><b>img: </b> It represents the input image on which we have to write text\n",
    "<li><b>text: </b>The text which we want to write on the image.\n",
    "<li><b>org: </b>It denotes the Bottom-left corner of the text string on the image.So it is used to set the location of text on the image\n",
    "<li><b>font:</b> the font of text.Here is the list of supported fonts.\n",
    "<li><b>fontScale:</b> The scale of the font by which you can increase or decrease size\n",
    "<li><b>color: </b>Represents the color. We can pass a tuple For in BGR,  eg: (255, 0, 0) for blue color. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw green text on the image3\n",
    "import cv2\n",
    "font= cv2.FONT_HERSHEY_SIMPLEX\n",
    "output = image.copy()\n",
    "cv2.putText(output, \"OpenCV + write new text ...!!!\", (10, 25), \n",
    "    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "cv2.imshow(\"Text\", output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>The putText function of OpenCV is responsible for drawing text on an image. Let’s take a look at the required parameters:</b>\n",
    "\n",
    "<li><b>img : </b> The output image.\n",
    "<li><b>text : </b>The string of text we’d like to write/draw on the image.\n",
    "<li><b>pt : </b>The starting point for the text.\n",
    "<li><b>font : </b> I often use the cv2.FONT_HERSHEY_SIMPLEX . The available fonts are listed here.\n",
    "<li><b>scale : </b>Font size multiplier.\n",
    "<li><b>color : </b>Text color.\n",
    "<li><b>thickness : </b>The thickness of the stroke in pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>OpenCV Image Rotation</h3>\n",
    "cv2.rotate() used to rotate a 2D array in multiples of 90 degrees.Here is the syntax:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Syntax: cv2.rotate( src, rotateCode[, dst] )</b>\n",
    "Parameters:\n",
    "<lI>src: It is the image to be rotated.\n",
    "<lI>rotateCode: It is an enum to specify how to rotate the array.Here are some of the possible values :\n",
    "<lI>  >>> cv2.cv2.ROTATE_90_CLOCKWISE\n",
    "<lI>  >>> cv2.ROTATE_180\n",
    "<lI>  >>> cv2.ROTATE_90_COUNTERCLOCKWISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(571, 475, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "#importing the opencv module  \n",
    "import cv2  \n",
    "# using imread('path') and 1 denotes read as  color image  \n",
    "#img = cv2.imread(\"Desktop/3.png\")\n",
    "print(img.shape)\n",
    "# image = cv2.rotate(img , cv2.ROTATE_90_COOUTERCLOCKWISE)\n",
    "image = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE) \n",
    "cv2.imshow(\"Rotated images 90 CCW\",image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now what if we want to rotate the image by <font color='red'>a certain angle</font>.We can use another method for that.First calculate the affine matrix that does the affine transformation (linear mapping of pixels) by using the getRotationMatrix2D method,next we warp the input image with the affine matrix using warpAffine method.Here is the syntax of these functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>syntax:</b>\n",
    "cv2.getRotationMatrix2D(center, angle, scale)<br>\n",
    "cv2.warpAffine(Img, M, (W, H))\n",
    "<li><b>center:</b> center of the image (the point about which rotation has to happen)\n",
    "<li><b>angle: </b>angle by which image has to be rotated in the anti-clockwise direction.\n",
    "<li><b>scale: </b>scales the image by the value provided,1.0 means the shape is preserved.\n",
    "<li><b>H:</b>height of image\n",
    "<li><b>W:</b> width of the image.\n",
    "<li><b>M: </b>affine matrix returned by cv2.getRotationMatrix2D\n",
    "<li><b>Img:</b>image to be rotated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.123234e-17  1.000000e+00  4.800000e+01]\n",
      " [-1.000000e+00  6.123234e-17  5.230000e+02]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "(h,w) = img.shape[:2]\n",
    "\n",
    "center = (h/2 , w /2)\n",
    "\n",
    "M = cv2.getRotationMatrix2D( center,90 , 1)\n",
    "rotation_90 = cv2.warpAffine(img , M , (h,w) )\n",
    "cv2.imshow('rotate 90', rotation_90)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "print(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(571, 475)\n",
      "[[   0.70710678    0.70710678 -132.31684656]\n",
      " [  -0.70710678    0.70710678  251.5588745 ]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "#importing the opencv module  \n",
    "import cv2  \n",
    "# using imread('path') and 1 denotes read as  color image  \n",
    "# img = cv2.imread(\"Desktop/3.png\",1)  \n",
    "# get image height, width\n",
    "(h, w) = img.shape[:2]\n",
    "print(img.shape[:2])\n",
    "# calculate the center of the image\n",
    "center = (w / 2, h / 2)\n",
    "  \n",
    "scale = 1.0\n",
    "  \n",
    "# Perform the counter clockwise rotation holding at the center\n",
    "# 45 degrees\n",
    "M = cv2.getRotationMatrix2D(center, 45, scale)\n",
    "print(M)\n",
    "rotated45 = cv2.warpAffine(img, M, (h, w))\n",
    "  \n",
    "# 110 degrees\n",
    "M = cv2.getRotationMatrix2D(center,110, scale)\n",
    "rotated110 = cv2.warpAffine(img, M, (w, h))\n",
    "  \n",
    "# 150 degrees\n",
    "M = cv2.getRotationMatrix2D(center, 150, scale)\n",
    "rotated150 = cv2.warpAffine(img, M, (h, w))\n",
    "\n",
    "# 160 degree\n",
    "M =  cv2.getRotationMatrix2D(center , 160,scale)\n",
    "rotation160 =cv2.warpAffine(img ,M ,(h , w) )\n",
    "\n",
    "cv2.imshow('160 rotation ',rotation160)\n",
    "cv2.waitKey(0) # waits until a key is pressed\n",
    "cv2.destroyAllWindows() \n",
    "\n",
    "cv2.imshow('Original Image',img)\n",
    "cv2.waitKey(0) # waits until a key is pressed\n",
    "cv2.destroyAllWindows() # destroys the window showing image\n",
    "  \n",
    "cv2.imshow('Image rotated by 45 degrees',rotated45)\n",
    "cv2.waitKey(0) # waits until a key is pressed\n",
    "cv2.destroyAllWindows() # destroys the window showing image\n",
    "  \n",
    "cv2.imshow('Image rotated by 110 degrees',rotated110)\n",
    "cv2.waitKey(0) # waits until a key is pressed\n",
    "cv2.destroyAllWindows() # destroys the window showing image\n",
    "  \n",
    "cv2.imshow('Image rotated by 150 degrees',rotated150)\n",
    "cv2.waitKey(0) # waits until a key is pressed\n",
    "cv2.destroyAllWindows() # destroys the window showing image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "475\n",
      "571\n",
      "(475, 571, 3)\n"
     ]
    }
   ],
   "source": [
    "# print(w)\n",
    "# print(h)\n",
    "# print(image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Canny Edge Detection</h3>\n",
    "Edge detection is an image processing technique used for finding the boundaries of objects within images.Here we will use a popular edge detection algorithm Canny Edge Detection, developed by John F. Canny.In OpenCV, we have Canny() method to implement this algorithm.Here is the syntax:\n",
    "\n",
    "edges = cv2.Canny(img, minVal, maxVal, apertureSize, L2gradient)  \n",
    "<b>Parameters-</b>\n",
    "<li><b>img: </b> input image whose edges we want to detect.\n",
    "<li><b>minVal:</b> Minimum intensity gradient (required)\n",
    "<li><b>maxVal:</b> Maximum intensity gradient (required)\n",
    "<li><b>L2gradient:</b> is a flag with default value =False, indicating the default L1 norm is enough to calculate the image gradient magnitude,If its is set as True a more accurate L2 norm is used to calculate the image gradient magnitude but it is computationally more expensive.\n",
    "<li><b>aperture: </b>aperture size for the Sobel operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img = cv2.imread(r\"C:\\Users\\Elhamd Pc\\Pictures\\Screenshots\\Screenshot 2023-10-10 230514.png\")\n",
    "edges = cv2.Canny(img,50,100,True)\n",
    "cv2.imshow(\"Edge Detected Image\", edges)  \n",
    "cv2.imshow(\"Original Image\", img)  \n",
    "cv2.waitKey(0)  # waits until a key is pressed  \n",
    "cv2.destroyAllWindows()  # destroys the window showing image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> <font color='red'>Canny in real-time: Video</font></h3>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries of python OpenCV    \n",
    "import cv2  \n",
    "   \n",
    "# import Numpy by alias name np  \n",
    "import numpy as np  \n",
    "   \n",
    "# capture frames from a camera   \n",
    "cap = cv2.VideoCapture(0)  \n",
    "   \n",
    "# loop runs if capturing has been initialized   \n",
    "while (1):  \n",
    "   \n",
    "    # reads frames from a camera   \n",
    "    ret, frame = cap.read()  \n",
    "   \n",
    "    # Display an original image   \n",
    "    cv2.imshow('Original', frame)  \n",
    "   \n",
    "    # discovers edges in the input image image and   \n",
    "    # marks them in the output map edges   \n",
    "   # edges = cv2.Canny(frame, 100, 200,True)  \n",
    "    cv2.imshow('cv2.GaussianBlur output', cv2.GaussianBlur(frame, (5, 5), cv2.BORDER_DEFAULT)) \n",
    "    # Display edges in a frame   \n",
    "    #cv2.imshow('Edges', edges)  \n",
    "   \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "   \n",
    "# Close the window   \n",
    "cap.release()  \n",
    "   \n",
    "# De-allocate any associated memory usage   \n",
    "cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>OpenCV Image Smoothing</h3>\n",
    "    > Image smoothing is an image processing technique used for removing the noise in an image.Blurring(smoothing) removes low-intensity edges and is also beneficial in hiding the details; for example, blurring is required in many cases, such as hiding any confidential information in an image.OpenCV provides mainly the following type of blurring techniques.\n",
    "\n",
    "<li><b>OpenCV averaging</b></li>\n",
    "<li><b>OpenCV median Blur</b></li>\n",
    "<li><b>OpenCV Gaussian Blur</b></li>\n",
    "<li><b>OpenCV Bilateral Filter</b></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:971: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18112\\347733596.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Desktop/3.png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Original Image'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cv2.blur output'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblur\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:971: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "img = cv2.imread(\"Desktop/3.png\")\n",
    "cv2.imshow('Original Image',img)  \n",
    "cv2.imshow('cv2.blur output', cv2.blur(img, (3,3)))  \n",
    "cv2.waitKey(0)  \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li><b>OpenCV median Blur</b></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OpenCV median Blur\n",
    "import cv2\n",
    "img = cv2.imread(\"Desktop/3.png\")\n",
    "cv2.imshow('Original Image',img)  \n",
    "cv2.imshow('cv2.medianBlur output', cv2.medianBlur(img,5))  \n",
    "cv2.waitKey(0)  \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li><b>OpenCV Gaussian Blur</b></li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OpenCV Gaussian Blur\n",
    "import cv2\n",
    "img = cv2.imread(\"Desktop/3.png\")\n",
    "cv2.imshow('Original Image',img)  \n",
    "cv2.imshow('cv2.GaussianBlur output', cv2.GaussianBlur(img, (5, 5), cv2.BORDER_DEFAULT))     \n",
    "cv2.waitKey(0)  \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li><b>OpenCV Bilateral Filter</b></li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OpenCV Bilateral Filter\n",
    "import cv2\n",
    "img = cv2.imread(\"4.png\")\n",
    "cv2.imshow('Original Image',img)  \n",
    "cv2.imshow('bilateral Image', cv2.bilateralFilter(img,9,75,75))  \n",
    "cv2.waitKey(0)  \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>OpenCV Image Threshold</h3>\n",
    "<b>Thresholding </b>is a popular segmentation technique, used for separating an object considered as a foreground from its background.In this technique we assign pixel values in relation to the threshold value provided.This technique of thresholding is done on grayscale images,so initially, the image has to be converted in grayscale color space.Here we will discuss two different approaches taken when performing thresholding on an image:\n",
    "\n",
    "<li><b>Simple Thresholding</b>\n",
    "<li><b>Adaptive Thresholding</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Simple Thresholding:</b>\n",
    "In this basic Thresholding technique, for every pixel, the same threshold value is applied. If the pixel value is smaller than the threshold, it is set to a certain value(usually zero) , otherwise, it is set to another value(usually maximum value) .There are various variations of this technique as shown below.\n",
    "\n",
    "In OpenCV, <b>cv2.threshold </b>function to implement it.Here is the syntax:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>cv2.threshold(source, thresholdValue, maxVal, thresholdingTechnique)</b>\n",
    "\n",
    "<b>Parameters:<br></b>\n",
    "<li> <b> source: </b>Input Image array (must be in Grayscale).<br>\n",
    "<li> <b> thresholdValue:</b> Value of Threshold below and above which pixel values will change accordingly.<br>\n",
    "<li> <b> maxVal: </b>Maximum value that can be assigned to a pixel.<br>\n",
    "<li> <b> thresholdingTechnique: </b>The type of thresholding to be applied.Here are various types of thresholding we can use:\n",
    "\n",
    "<li> <b> >> cv2.THRESH_BINARY: </b>If  the pixel intensity is greater than the threshold, the pixel value is set to 255(white), else it is set to 0 (black).\n",
    "<li> <b> >> cv2.THRESH_BINARY_INV:</b> Inverted or Opposite case of cv2.THRESH_BINARY.If  the pixel intensity is greater than the threshold, the pixel value is set to 0(black), else it is set to 255 (white).\n",
    "<li> <b> >> cv.THRESH_TRUNC: </b>If  the pixel intensity is greater than the threshold,the pixel values are set to be the same as the threshold. All other values remain the same.\n",
    "<li> <b> >> cv.THRESH_TOZERO:</b> Pixel intensity is set to 0, for all the pixels intensity, less than the threshold value.All other pixel values remain same\n",
    "<li> <b> >> cv.THRESH_TOZERO_INV:</b> Inverted or Opposite case of cv2.THRESH_TOZERO. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140.0\n"
     ]
    }
   ],
   "source": [
    "import cv2  \n",
    "import numpy as np  \n",
    "   \n",
    "# path to input image is specified and   \n",
    "# image is loaded with imread command  \n",
    "image = cv2.imread(r\"C:\\Users\\Elhamd Pc\\Pictures\\Screenshots\\Screenshot 2023-10-10 230514.png\")  \n",
    "   \n",
    " \n",
    "# to convert the image in grayscale  \n",
    "img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
    "   \n",
    "threshold=140\n",
    "ret, thresh1 = cv2.threshold(img, threshold, 255, cv2.THRESH_BINARY) \n",
    "ret, thresh2 = cv2.threshold(img, threshold, 255, cv2.THRESH_BINARY_INV) \n",
    "ret, thresh3 = cv2.threshold(img, threshold, 255, cv2.THRESH_TRUNC) \n",
    "ret, thresh4 = cv2.threshold(img, threshold, 255, cv2.THRESH_TOZERO) \n",
    "ret, thresh5 = cv2.threshold(img, threshold, 255, cv2.THRESH_TOZERO_INV) \n",
    "print(ret)   \n",
    "# the window showing output images \n",
    "# with the corresponding thresholding  \n",
    "# techniques applied to the input images \n",
    "cv2.imshow('Original',image)\n",
    "cv2.imshow('Binary Threshold', thresh1) \n",
    "cv2.imshow('Binary Threshold Inverted', thresh2) \n",
    "cv2.imshow('Truncated Threshold', thresh3) \n",
    "cv2.imshow('Zero Threshold', thresh4) \n",
    "cv2.imshow('Zero Inverted', thresh5) \n",
    "     \n",
    "# De-allocate any associated memory usage   \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Adaptive Thresholding:</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In simple thresholding,the threshold value was global which means it was same for all the pixels in the image.But this may not be the best approach for thresholding as the different image sections can have different lightings.Thus we need Adaptive thresholding,which is the method where the threshold value is calculated for smaller regions and therefore, there will be different threshold values for different regions.In OpenCV we have adaptiveThreshold() function to implement this type of thresholding.Here is the syntax of this function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>adaptiveThreshold(src, dst, maxValue, adaptiveMethod, thresholdType, blockSize, C)</b>\n",
    "This method accepts the following parameters −\n",
    "\n",
    "<li><b>src −</b> An object of the class Mat representing the source (input) image.\n",
    "<li><b>dst − </b>An object of the class Mat representing the destination (output) image.\n",
    "<li><b>maxValue − </b>A variable of double type representing the value that is to be given if pixel value is more than the threshold value.\n",
    "<li><b>adaptiveMethod −</b> A variable of integer the type representing the adaptive method to be used.<br> \n",
    "    >>>>>> cv.ADAPTIVE_THRESH_MEAN_C: The threshold value is the mean of the neighbourhood area minus the constant C.<br>\n",
    "    >>>>>> cv.ADAPTIVE_THRESH_GAUSSIAN_C: The threshold value is a gaussian-weighted sum of the neighbourhood values minus the constant C.\n",
    "\n",
    "<li><b>thresholdType </b>− A variable of integer type representing the type of threshold to be used.\n",
    "<li><b>blockSize − </b>A variable of the integer type representing size of the pixelneighborhood used to calculate the threshold value.\n",
    "C − A variable of double type representing the constant used in the both methods (subtracted from the mean or weighted mean)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adaptive threshold\n",
    "import cv2  \n",
    "import numpy as np  \n",
    "   \n",
    "# path to input image is specified and   \n",
    "# image is loaded with imread command  \n",
    "image = cv2.imread(r\"C:\\Users\\Elhamd Pc\\Pictures\\Screenshots\\Screenshot 2023-10-10 230514.png\")  \n",
    "   \n",
    " \n",
    "# to convert the image in grayscale  \n",
    "img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "ret, th1 = cv2.threshold(img,160, 255, cv2.THRESH_BINARY) \n",
    "   \n",
    "th2 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "            cv2.THRESH_BINARY,11,2)\n",
    "th3 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "            cv2.THRESH_BINARY,11,2)\n",
    " \n",
    "cv2.imshow('Original',image)\n",
    "cv2.imshow('Binary Threshold', th1) \n",
    "cv2.imshow('Adaptive Threshold', th2) \n",
    "cv2.imshow('Gaussain Adaptive Threshold', th3) \n",
    "     \n",
    "# De-allocate any associated memory usage   \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
